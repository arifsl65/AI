{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arifsl65/AI/blob/main/cuda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHnyRi93gna0",
        "outputId": "88d75483-5429-4857-be46-3de687bf024e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n",
            "GPU Name: Tesla T4\n",
            "Current GPU: 0\n",
            "GPU Count: 1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "\n",
        "# Check GPU info\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
        "    print(\"Current GPU:\", torch.cuda.current_device())\n",
        "    print(\"GPU Count:\", torch.cuda.device_count())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import time\n",
        "\n",
        "# Create large matrices\n",
        "size = 5000\n",
        "a = torch.randn(size, size)\n",
        "b = torch.randn(size, size)\n",
        "\n",
        "# CPU computation\n",
        "start_time = time.time()\n",
        "cpu_result = torch.matmul(a, b)\n",
        "cpu_time = time.time() - start_time\n",
        "print(f\"CPU Time: {cpu_time:.2f} seconds\")\n",
        "\n",
        "# GPU computation\n",
        "if torch.cuda.is_available():\n",
        "    # Move matrices to GPU\n",
        "    a_gpu = a.cuda()\n",
        "    b_gpu = b.cuda()\n",
        "\n",
        "    # Warm up GPU\n",
        "    torch.matmul(a_gpu, b_gpu)\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "    # Measure GPU time\n",
        "    start_time = time.time()\n",
        "    gpu_result = torch.matmul(a_gpu, b_gpu)\n",
        "    torch.cuda.synchronize()\n",
        "    gpu_time = time.time() - start_time\n",
        "    print(f\"GPU Time: {gpu_time:.2f} seconds\")\n",
        "    print(f\"GPU is {cpu_time/gpu_time:.1f}x faster\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_RJuhOXiPDE",
        "outputId": "d51ceb8d-fe50-45f6-afde-98f4cba70cb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU Time: 4.30 seconds\n",
            "GPU Time: 0.09 seconds\n",
            "GPU is 49.0x faster\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Check if we're still on GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define the neural network\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(28 * 28, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        return self.layers(x)\n",
        "\n",
        "# Load and preprocess MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "# Download training data\n",
        "train_dataset = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Create the model and move it to GPU\n",
        "model = SimpleNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # Move data to GPU\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        _, predicted = output.max(1)\n",
        "        total += target.size(0)\n",
        "        correct += predicted.eq(target).sum().item()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if batch_idx % 100 == 99:    # Print every 100 batches\n",
        "            print(f'Epoch: {epoch + 1}, Batch: {batch_idx + 1}, Loss: {running_loss / 100:.3f}, Accuracy: {100. * correct / total:.2f}%')\n",
        "            running_loss = 0.0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "\n",
        "print('Training finished!')\n",
        "\n",
        "# Test the model on a single example\n",
        "test_dataset = datasets.MNIST('data', train=False, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
        "data, target = next(iter(test_loader))\n",
        "data = data.to(device)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    output = model(data)\n",
        "    predicted = output.argmax().item()\n",
        "\n",
        "print(f\"\\nPredicted digit: {predicted}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RViDI98A85Cz",
        "outputId": "b50fac68-1d4c-4832-ced7-dd881d989863"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:11<00:00, 898kB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 134kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.27MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.44MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Epoch: 1, Batch: 100, Loss: 0.709, Accuracy: 79.94%\n",
            "Epoch: 1, Batch: 200, Loss: 0.348, Accuracy: 89.77%\n",
            "Epoch: 1, Batch: 300, Loss: 0.276, Accuracy: 91.83%\n",
            "Epoch: 1, Batch: 400, Loss: 0.240, Accuracy: 92.73%\n",
            "Epoch: 1, Batch: 500, Loss: 0.219, Accuracy: 93.30%\n",
            "Epoch: 1, Batch: 600, Loss: 0.182, Accuracy: 94.55%\n",
            "Epoch: 1, Batch: 700, Loss: 0.190, Accuracy: 94.23%\n",
            "Epoch: 1, Batch: 800, Loss: 0.159, Accuracy: 95.08%\n",
            "Epoch: 1, Batch: 900, Loss: 0.146, Accuracy: 95.53%\n",
            "Epoch: 2, Batch: 100, Loss: 0.125, Accuracy: 96.02%\n",
            "Epoch: 2, Batch: 200, Loss: 0.125, Accuracy: 96.12%\n",
            "Epoch: 2, Batch: 300, Loss: 0.121, Accuracy: 96.19%\n",
            "Epoch: 2, Batch: 400, Loss: 0.117, Accuracy: 96.42%\n",
            "Epoch: 2, Batch: 500, Loss: 0.120, Accuracy: 96.25%\n",
            "Epoch: 2, Batch: 600, Loss: 0.112, Accuracy: 96.70%\n",
            "Epoch: 2, Batch: 700, Loss: 0.105, Accuracy: 96.61%\n",
            "Epoch: 2, Batch: 800, Loss: 0.103, Accuracy: 96.59%\n",
            "Epoch: 2, Batch: 900, Loss: 0.097, Accuracy: 97.02%\n",
            "Epoch: 3, Batch: 100, Loss: 0.080, Accuracy: 97.44%\n",
            "Epoch: 3, Batch: 200, Loss: 0.083, Accuracy: 97.41%\n",
            "Epoch: 3, Batch: 300, Loss: 0.080, Accuracy: 97.78%\n",
            "Epoch: 3, Batch: 400, Loss: 0.077, Accuracy: 97.64%\n",
            "Epoch: 3, Batch: 500, Loss: 0.088, Accuracy: 97.20%\n",
            "Epoch: 3, Batch: 600, Loss: 0.079, Accuracy: 97.47%\n",
            "Epoch: 3, Batch: 700, Loss: 0.086, Accuracy: 97.25%\n",
            "Epoch: 3, Batch: 800, Loss: 0.077, Accuracy: 97.64%\n",
            "Epoch: 3, Batch: 900, Loss: 0.066, Accuracy: 98.08%\n",
            "Epoch: 4, Batch: 100, Loss: 0.049, Accuracy: 98.42%\n",
            "Epoch: 4, Batch: 200, Loss: 0.048, Accuracy: 98.41%\n",
            "Epoch: 4, Batch: 300, Loss: 0.053, Accuracy: 98.17%\n",
            "Epoch: 4, Batch: 400, Loss: 0.072, Accuracy: 97.84%\n",
            "Epoch: 4, Batch: 500, Loss: 0.069, Accuracy: 97.58%\n",
            "Epoch: 4, Batch: 600, Loss: 0.058, Accuracy: 98.09%\n",
            "Epoch: 4, Batch: 700, Loss: 0.063, Accuracy: 98.02%\n",
            "Epoch: 4, Batch: 800, Loss: 0.069, Accuracy: 97.83%\n",
            "Epoch: 4, Batch: 900, Loss: 0.068, Accuracy: 97.98%\n",
            "Epoch: 5, Batch: 100, Loss: 0.037, Accuracy: 98.81%\n",
            "Epoch: 5, Batch: 200, Loss: 0.038, Accuracy: 98.80%\n",
            "Epoch: 5, Batch: 300, Loss: 0.041, Accuracy: 98.73%\n",
            "Epoch: 5, Batch: 400, Loss: 0.044, Accuracy: 98.64%\n",
            "Epoch: 5, Batch: 500, Loss: 0.053, Accuracy: 98.25%\n",
            "Epoch: 5, Batch: 600, Loss: 0.056, Accuracy: 98.23%\n",
            "Epoch: 5, Batch: 700, Loss: 0.044, Accuracy: 98.59%\n",
            "Epoch: 5, Batch: 800, Loss: 0.048, Accuracy: 98.30%\n",
            "Epoch: 5, Batch: 900, Loss: 0.054, Accuracy: 98.31%\n",
            "Training finished!\n",
            "\n",
            "Predicted digit: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "def predict_uploaded_image():\n",
        "    # Upload image through Colab\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # Get the uploaded image\n",
        "    image_name = next(iter(uploaded))\n",
        "    image = Image.open(io.BytesIO(uploaded[image_name])).convert('L')  # Convert to grayscale\n",
        "    image = image.resize((28, 28))\n",
        "\n",
        "    # Transform image\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "    # Prepare image for model\n",
        "    img_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    # Get prediction\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(img_tensor)\n",
        "        predicted = output.argmax().item()\n",
        "\n",
        "    print(f\"Predicted digit: {predicted}\")\n",
        "\n",
        "    # Display the image\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.imshow(image, cmap='gray')\n",
        "    plt.title(f'Predicted: {predicted}')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Run the prediction\n",
        "predict_uploaded_image()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "D7lLZ83e-hC0",
        "outputId": "d34a6dc6-8b53-4141-a305-63fff2d7ccd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e00d24ba-9b63-43ad-95b6-189a0199d88d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e00d24ba-9b63-43ad-95b6-189a0199d88d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving fyPhv.jpg to fyPhv.jpg\n",
            "Predicted digit: 7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}